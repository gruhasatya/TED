{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Data Preparation\n",
        "# First, we need to download the dataset from the Hugging Face library using the datasets package."
      ],
      "metadata": {
        "id": "JOU3WL9Pnnig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset('emotion')\n"
      ],
      "metadata": {
        "id": "w3mT_5O6m7zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Next, we need to preprocess the data. We will use the transformers library from Hugging Face to tokenize the tweets and convert them to numerical sequences that can be used as input to our deep learning model."
      ],
      "metadata": {
        "id": "RkyIxs3Inovk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def preprocess(example):\n",
        "    text = example['text']\n",
        "    label = example['label']\n",
        "    inputs = tokenizer.encode_plus(text, add_special_tokens=True, return_tensors='tf')\n",
        "    return inputs['input_ids'], inputs['attention_mask'], label\n",
        "\n",
        "# Preprocess the dataset\n",
        "dataset = dataset.map(preprocess, batched=True)\n"
      ],
      "metadata": {
        "id": "pwSJVFbynJ0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Building\n",
        "# For our text emotion detection task, we will use the BERT (Bidirectional Encoder Representations from Transformers) model,\n",
        "#  which is a pre-trained language model that has achieved state-of-the-art performance on many natural language processing tasks."
      ],
      "metadata": {
        "id": "rJ5pc5pHn5YK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from transformers import TFBertModel\n",
        "\n",
        "# Load the pre-trained BERT model\n",
        "bert = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Freeze the BERT model layers\n",
        "for layer in bert.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Define the input layers\n",
        "input_ids = Input(shape=(None,), dtype=tf.int32, name='input_ids')\n",
        "attention_mask = Input(shape=(None,), dtype=tf.int32, name='attention_mask')\n",
        "\n",
        "# Pass the inputs through the BERT model\n",
        "output = bert({'input_ids': input_ids, 'attention_mask': attention_mask})[1]\n",
        "\n",
        "# Add a dense layer with dropout for classification\n",
        "output = Dense(256, activation='relu')(output)\n",
        "output = Dropout(0.2)(output)\n",
        "output = Dense(128, activation='relu')(output)\n",
        "output = Dropout(0.2)(output)\n",
        "output = Dense(4, activation='softmax')(output)\n",
        "\n",
        "# Define the model inputs and outputs\n",
        "model = Model(inputs=[input_ids, attention_mask], outputs=output)\n"
      ],
      "metadata": {
        "id": "HEws2J1rnMFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "# This code splits the preprocessed dataset into training and testing sets and defines the batch size and number of epochs for training. \n",
        "# It compiles the model with categorical cross-entropy loss and Adam optimizer and defines the training and validation data generators. Finally,\n",
        "#  it trains the model and saves the training history for later analysis."
      ],
      "metadata": {
        "id": "kUw0WXoHoDDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "train_dataset = dataset['train']\n",
        "test_dataset = dataset['test']\n",
        "\n",
        "# Define the batch size and number of epochs\n",
        "batch_size = 32\n",
        "epochs = 3\n",
        "\n",
        "# Compile the model with categorical cross-entropy loss and Adam optimizer\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Define the training and validation data generators\n",
        "train_generator = tf.data.Dataset.from_tensor_slices(({'input_ids': train_dataset['input_ids'], 'attention_mask': train_dataset['attention_mask']}, tf.keras.utils.to_categorical(train_dataset['label'], num_classes=4)))\n",
        "train_generator = train_generator.shuffle(len(train_dataset)).batch(batch_size)\n",
        "\n",
        "test_generator = tf.data.Dataset.from_tensor_slices(({'input_ids': test_dataset['input_ids'], 'attention_mask': test_dataset['attention_mask']}, tf.keras.utils.to_categorical(test_dataset['label'], num_classes=4)))\n",
        "test_generator = test_generator.batch(batch_size)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=epochs, validation_data=test_generator)\n"
      ],
      "metadata": {
        "id": "Qzx8dtaInMJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Testing"
      ],
      "metadata": {
        "id": "8nzPmkn1oHqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f'Test accuracy: {test_acc:.2f}')\n"
      ],
      "metadata": {
        "id": "u72YThOTnMLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Deployment\n",
        "# Next, we will convert the trained model to the ONNX format and deploy it using the ONNX runtime.\n",
        "# This code first converts the trained TensorFlow model to the ONNX format and saves it to a file.\n",
        "#  Then, it defines the input and output names for the ONNX model and creates a session to run the model.\n",
        "#   Finally, it defines a function to run the model on a single input example and tests the function with a sample input."
      ],
      "metadata": {
        "id": "x4M-jQF2oXf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime\n",
        "import onnxruntime as rt\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# Convert the model to the ONNX format\n",
        "onnx_model = onnx.load_model_from_json(model.to_json())\n",
        "onnx.checker.check_model(onnx_model)\n",
        "onnx.save_model(onnx_model, 'emotion_detection.onnx')\n",
        "\n",
        "# Define the input and output names for the ONNX model\n",
        "input_name = model.input_names[0]\n",
        "output_name = model.output_names[0]\n",
        "\n",
        "# Create a session to run the ONNX model\n",
        "sess = rt.InferenceSession('emotion_detection.onnx')\n",
        "\n",
        "# Define a function to run the ONNX model on a single input example\n",
        "def predict(text):\n",
        "    inputs = tokenizer.encode_plus(text, add_special_tokens=True, return_tensors='np')\n",
        "    input_ids = inputs['input_ids']\n",
        "    attention_mask = inputs['attention_mask']\n",
        "    output = sess.run([output_name], {input_name: input_ids, 'attention_mask': attention_mask})[0]\n",
        "    return np.argmax(output)\n",
        "\n",
        "# Test the ONNX model with a sample input\n",
        "text = 'I am so happy!'\n",
        "label_map = {0: 'anger', 1: 'fear', 2: 'joy', 3: 'sadness'}\n",
        "prediction = predict(text)\n",
        "print(f'Text: {text}')\n",
        "print(f'Predicted emotion: {label_map[prediction]}')\n"
      ],
      "metadata": {
        "id": "YeKx-jncnMOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interface Creation\n",
        "# This code defines a Flask app with two routes: the home page and the predict page. The home page renders an HTML template with a text input and a submit button,\n",
        "# while the predict page receives the input text, runs the predict function, and renders an HTML template with the predicted emotion and the original text.\n",
        "\n",
        "# To run this app, save the code as a Python file (e.g., app.py), create the two HTML templates (index.html and result.html), and run the app with the following command in the terminal:"
      ],
      "metadata": {
        "id": "35oX45zKoaBI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask\n",
        "\n",
        "from flask import Flask, render_template, request\n",
        "\n",
        "# Define the Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Define the label map\n",
        "label_map = {0: 'anger', 1: 'fear', 2: 'joy', 3: 'sadness'}\n",
        "\n",
        "# Define the ONNX runtime session\n",
        "sess = rt.InferenceSession('emotion_detection.onnx')\n",
        "input_name = sess.get_inputs()[0].name\n",
        "output_name = sess.get_outputs()[0].name\n",
        "\n",
        "# Define the predict function\n",
        "def predict(text):\n",
        "    inputs = tokenizer.encode_plus(text, add_special_tokens=True, return_tensors='np')\n",
        "    input_ids = inputs['input_ids']\n",
        "    attention_mask = inputs['attention_mask']\n",
        "    output = sess.run([output_name], {input_name: input_ids, 'attention_mask': attention_mask})[0]\n",
        "    return np.argmax(output)\n",
        "\n",
        "# Define the Flask routes\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict_emotion():\n",
        "    text = request.form['text']\n",
        "    prediction = predict(text)\n",
        "    emotion = label_map[prediction]\n",
        "    return render_template('result.html', emotion=emotion, text=text)\n",
        "\n",
        "# Run the Flask app\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "id": "pejqoUJHnMSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python app.py\n"
      ],
      "metadata": {
        "id": "j5szr9gNnMU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Then, open a web browser and go to http://localhost:5000 to access the app.\n",
        "\n",
        "# This concludes the tutorial on text emotion detection using a pre-trained model from the Hugging Face library, TensorFlow, and ONNX runtime."
      ],
      "metadata": {
        "id": "rAP5P_oFnMYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In summary, we covered the following steps:\n",
        "\n",
        "# Load the dataset: We used the Microsoft Emotion Detection dataset from the Hugging Face library.\n",
        "\n",
        "# Preprocess the dataset: We split the dataset into training and testing sets, and performed text preprocessing steps such as tokenization and padding.\n",
        "\n",
        "# Train the model: We fine-tuned a pre-trained BERT model using TensorFlow to predict the emotions from the text.\n",
        "\n",
        "# Evaluate the model: We evaluated the model on the test set and computed the accuracy and F1 score.\n",
        "\n",
        "# Export the model: We converted the TensorFlow model to ONNX format for deployment.\n",
        "\n",
        "# Deploy the model: We used the ONNX runtime to load the model and make predictions, and created a Flask app with an interface for users to input text and get the predicted emotion.\n",
        "\n",
        "# With this tutorial, you should now have a good understanding of how to perform text emotion detection using pre-trained models and deploy the model for use in a real-world application."
      ],
      "metadata": {
        "id": "b31dq_14o5Al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To improve the model performance, there are several techniques we can try:\n",
        "\n",
        "# Hyperparameter tuning: We can tune the hyperparameters of the BERT model, such as the learning rate, batch size, and number of epochs, to find the optimal values for the dataset.\n",
        "\n",
        "# Ensemble learning: We can combine multiple models, such as BERT and other pre-trained models like RoBERTa or XLNet, to improve the overall performance.\n",
        "\n",
        "# Data augmentation: We can generate additional training data by applying techniques like back-translation, synonym replacement, and random insertion to increase the diversity of the dataset.\n",
        "\n",
        "# Transfer learning: We can fine-tune the BERT model on a larger, more diverse dataset, such as the Common Crawl corpus, to improve its ability to generalize to different domains.\n",
        "\n",
        "# Model compression: We can apply techniques like pruning, quantization, and distillation to reduce the size of the model and improve its efficiency for deployment on resource-constrained devices.\n",
        "\n",
        "# In addition to these techniques, there are also other pre-trained models and libraries available for text emotion detection, such as the DistilBERT, ALBERT, and ELECTRA models, and the PyTorch library.\n",
        "# Experimenting with different models and techniques can help us find the best approach for our specific use case."
      ],
      "metadata": {
        "id": "Yfmw_n-Vo5Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally, it's important to keep in mind some limitations and ethical considerations when using text emotion detection models.\n",
        "\n",
        "# One limitation is that these models may not always accurately capture the nuances and complexities of human emotions.\n",
        "# Emotions can be subjective and context-dependent, and people may express them in different ways. Models trained on one dataset may not generalize well to other datasets or domains,\n",
        "# and may exhibit biases based on the data they were trained on.\n",
        "\n",
        "# Another limitation is the potential for misuse or harm. Emotion detection models could be used to manipulate or exploit people's emotions, such as by targeting them with personalized ads or propaganda.\n",
        "# They could also be used for surveillance or monitoring purposes, such as to screen job applicants or track employees' emotional states.\n",
        "#  It's important to consider the ethical implications of using these models and to ensure that they are deployed in a responsible and transparent way.\n",
        "\n",
        "# In summary, text emotion detection is a useful application of natural language processing that has many potential use cases,from sentiment analysis in social media to customer feedback analysis in business.\n",
        "# By using pre-trained models and deploying them in a user-friendly interface,we can make this technology more accessible and useful for a wide range of applications.\n",
        "# However, it's important to be aware of the limitations and ethical considerations associated with this technology and to use it responsibly."
      ],
      "metadata": {
        "id": "_HPg8pG-o5VI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}